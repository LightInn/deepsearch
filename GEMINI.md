Alright. Hereâ€™s a fresh, *dense & actionable* blueprint describing your improved **CLI Rust research assistant**, taking into account all your new constraints and logic. Cynical curiosity included.

---

# ğŸ“ **Blueprint: Modular AI-Powered Research CLI (Rust)**

## ğŸ¯ **Project Scope & Principles**

* Single binary CLI app, Unix-friendly.
* External dependencies:

  * Local LLM (Ollama, JSON output mode, `ollama-rs` crate).
  * Search via Wikipedia API & DuckDuckGo HTML scraping.
* Orchestrates **step-by-step research**:

  * Decompose â†’ Search â†’ Filter â†’ Summarize â†’ Evaluate â†’ Iterate â†’ Answer.
* Prioritize **validity & coherence** of data (names, dates, etc.).
* Minimal CLI UI â€” no `ratatui`, just `clap`, `colored` and some Unicode flair.
* User chooses Ollama model at startup (from detected list).
* Avoid unnecessary Ollama calls â€” reduce context bloat & chat loops.

---

## ğŸªœ **Logic: Research Workflow**

```
ğŸ” Question â†’ ğŸ¤” Decompose â†’ ğŸ§­ Select tools â†’ ğŸŒ Search â†’ ğŸ—‚ï¸ Filter results 
â†’ ğŸ“„ Scrape & Summarize â†’ ğŸ§  Evaluate â†’ ğŸ§© (Iterate if needed) â†’ âœ… Answer
```

### Step-by-Step

1ï¸âƒ£ **Decompose the question**

* Send main question to Ollama:

  > *"Break down this complex question into concrete, specific sub-questions needed to answer it step by step. Reply in JSON list of strings."*
* Parse JSON list.

2ï¸âƒ£ **Decide per sub-question: search tool**

* For each sub-question, decide:

  * Wikipedia if clearly factual or well-defined topic.
  * DuckDuckGo otherwise.
* Query Ollama to rank tools if ambiguous (optional).

3ï¸âƒ£ **Search & collect results**

* Use:

  * Wikipedia API (structured JSON)
  * DuckDuckGo (HTML scrape + parse).
* Discard irrelevant sources: closed platforms (Facebook, Twitter, etc).

4ï¸âƒ£ **Filter URLs for relevance**

* Prompt Ollama:

  > *"Given these URLs and the sub-question, which ones are most relevant, trustworthy, and coherent with the questionâ€™s constraints (names, dates, etc.)? Return JSON of relevant URLs & titles."*

5ï¸âƒ£ **Scrape & summarize each page**

* Fetch content.
* Parse into readable text.
* Chunk if too long.
* Summarize with Ollama (keep it scoped to sub-question & avoid overloading context).

6ï¸âƒ£ **Evaluate**

* Aggregate summaries into `global_context`.
* Ask Ollama:

  > *"Based on this global context, can you answer the main question? If not, suggest refined sub-questions."*
* If yes â†’ Output synthetic answer.
* If no â†’ Loop with new sub-questions.

7ï¸âƒ£ **Final checks**

* Ensure coherence of output (e.g., names, dates).
* Clean, concise markdown-style output.

---

## ğŸ§© **CLI UI**

* User selects Ollama model at startup (list fetched via `ollama-rs`).
* Command example:

  ```
  deepsearch "How did the 2008 financial crisis impact European banking regulation?" --max-depth 3 --model llama3
  ```
* Output: minimal, readable, with section headings & emojis:

  ```
  ğŸ§© Decomposed sub-questions:
  1. â€¦
  2. â€¦
  â€¦

  ğŸ” Search results:
  â€¦

  ğŸ“„ Summaries:
  â€¦

  âœ… Final Answer:
  â€¦
  ```

---

## ğŸ—ƒï¸ **Architecture**

```
src/
â”œâ”€â”€ main.rs
â”œâ”€â”€ cli.rs           // clap CLI & UI output helpers
â”œâ”€â”€ orchestrator.rs  // workflow logic & loop
â”œâ”€â”€ ollama.rs        // ollama-rs interface & JSON parsing
â”œâ”€â”€ search.rs        // Wikipedia + DuckDuckGo
â”œâ”€â”€ parser.rs        // HTML scraping & text extraction
â”œâ”€â”€ context.rs       // global context management & validation
```

---

## ğŸ“ˆ **Optimizations**

* Always request `format=json` in Ollama prompts.
* Limit Ollama input: only pass minimal context & sub-question.
* Cache Ollama calls & fetched pages if running iteratively.
* Cap number of search results & page size early.
* Avoid full conversational history â€” stateless calls where possible.

---

## ğŸªµ **MVP Milestones**

| Milestone | What to implement                    |
| --------- | ------------------------------------ |
| âœ… 1       | CLI with question + model selection  |
| âœ… 2       | Ollama JSON call: decompose question |
| âœ… 3       | Wikipedia & DDG search               |
| âœ… 4       | Ollama JSON call: filter URLs        |
| âœ… 5       | Page scrape & summary                |
| âœ… 6       | Evaluation loop                      |
| âœ… 7       | Final answer output                  |

---

## ğŸ˜ˆ **Brutal Advice**

* Ollama context windows are brutal â€” keep each call scoped, and pre-trim content.
* Donâ€™t trust DDG HTML structure to stay stable â€” build a resilient parser, or consider Bing if this fails.
* Wikipedia API is your friend â€” prefer it whenever possible.
* Be skeptical about Ollama JSON output â€” validate & fallback.
* Never concatenate full-page texts into Ollama input â€” chunk & summarize progressively.

---

## ğŸ—‚ï¸ **Next Steps**

âœ… Bootstrap project & skeleton
âœ… Implement `ollama.rs` with model listing & JSON calls
âœ… Implement Wikipedia search module
ğŸ”œ Build orchestrator loop step by step
ğŸ”œ Focus on per-step validation & defensive coding

---

If you want, I can also draft:

âœ… a `main.rs` skeleton with CLI + orchestrator hook
âœ… `ollama.rs` JSON query/response parser example
âœ… example `orchestrator.rs` with a hardcoded 1-iteration loop

Say the word.
